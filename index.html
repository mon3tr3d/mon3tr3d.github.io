<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mon3tr: Test-time Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
    </style>
</head>
<body class="bg-white text-gray-800 antialiased">

    <header class="max-w-4xl mx-auto pt-16 pb-8 px-4 text-center">
        <h1 class="text-4xl md:text-5xl font-bold mb-6 leading-tight">
            Mon3tr: Test-time Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization<br>
        </h1>
        <div class="flex flex-wrap justify-center gap-6 text-lg mb-6">
                <span class="font-medium hover:text-blue-600 cursor-pointer">Fangyu Lin<sup>1</sup></span>
                <span class="font-medium hover:text-blue-600 cursor-pointer">Yingdong Hu<sup>1</sup></span>
                <span class="font-medium hover:text-blue-600 cursor-pointer">Zhening Liu<sup>1</sup></span>
                <span class="font-medium hover:text-blue-600 cursor-pointer">Yufan Zhuang<sup>1</sup></span>
                <span class="font-medium hover:text-blue-600 cursor-pointer">Zehong Lin<sup>1</sup></span>
                <span class="font-medium hover:text-blue-600 cursor-pointer">Jun Zhang<sup>1</sup></span>
        </div>
        <div class="text-gray-600 mb-8">
            <p><sup>1</sup>HKUST</p>
        </div>
        <div class="flex justify-center gap-4">
            <a href="#" class="flex items-center gap-2 bg-gray-900 text-white px-5 py-2 rounded-full hover:bg-gray-700 transition">
                <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>
                Paper
            </a>
            <a href="#" class="flex items-center gap-2 bg-gray-900 text-white px-5 py-2 rounded-full hover:bg-gray-700 transition">
                <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/></svg>
                Demo Code
            </a>
        </div>
    </header>

    <section class="max-w-4xl mx-auto px-4 mb-16">
        <div class="relative w-full overflow-hidden rounded-lg shadow-xl" style="padding-top: 56.25%;">
            <video
                class="w-full h-full object-cover"
                style="position: absolute; top: 0; left: 0;"
                src="./assets/Mon3tr.mp4"
                controls
                autoplay
                loop
                muted
                playsinline
            >
                您的浏览器不支持视频播放。
            </video>
        </div>
    </section>

    <section class="max-w-4xl mx-auto px-4 mb-16">
        <h2 class="text-2xl font-bold mb-4 border-b pb-2">Abstract</h2>
        <p class="text-gray-700 leading-relaxed text-justify">
            Immersive telepresence aims to transform human interaction in AR/VR applications by enabling lifelike full-body holographic representations for enhanced remote collaboration. 
            However, existing systems rely on hardware-intensive multi-camera setups and demand high bandwidth for volumetric streaming, limiting their real-time performance on mobile devices. 
            To overcome these challenges, we propose <strong>Mon3tr</strong>, a novel test-time <strong><u>Mon</u></strong>ocular <strong><u>3</u></strong>D <strong><u>t</u></strong>elep<strong><u>r</u></strong>esence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence for the first time. 
            Mon3tr adopts an amortized computation strategy, dividing the process into a one-time offline multi-view reconstruction phase to build a user-specific avatar and a monocular online inference phase during live telepresence sessions. 
            Using a single monocular RGB camera, it captures body motions and facial expressions in real time to drive the 3DGS-based parametric human model, significantly reducing system complexity and cost. 
            The extracted motion and appearance features are transmitted at &lt;0.2 Mbps over WebRTC’s data channel, allowing robust adaptation to network fluctuations. 
            On the receiver side, e.g., Meta Quest 3, we develop a lightweight 3DGS attribute deformation network to dynamically generate corrective 3DGS attribute adjustments on the pre-built avatar, synthesizing photorealistic motion and appearance at &sim; 60 FPS. 
            Extensive experiments demonstrate the state-of-the-art performance of our method, achieving a PSNR of &gt;28 dB for novel poses, an end-to-end latency of &sim; 80 ms, and &gt;1000&times; bandwidth reduction compared to point-cloud streaming, while supporting real-time operation from monocular inputs across diverse scenarios.
        </p>
    </section>

    <section class="max-w-4xl mx-auto px-4 mb-16">
        <h2 class="text-2xl font-bold mb-6 border-b pb-2">Method</h2>
        <div class="bg-white p-4 rounded-lg shadow-sm border border-gray-100">
            <img
                src="./assets/pipeline.svg"
                alt="Mon3tr System Architecture Diagram"
                class="w-full h-auto rounded"
            >
        </div>
        <p class="mt-4 text-gray-700">
            System overview of <strong>Mon3tr</strong>. Before the online immersive telepresence or conferencing, Mon3tr pre-builds a photorealistic animatable avatar based on pre-recorded video clips, which is then uploaded to a cloud server for subsequent use.
            During runtime, a monocular RGB camera captures and estimates SMPL, FLAME, and MANO parameters [gvhmr, hamer, smirk] in parallel and sends them to the VR viewer via a Wi-Fi router with controlled bandwidth [tc].
            The pre-built avatar is then driven in real time at ~ 60 FPS on the device.
        </p>
    </section>

<section class="max-w-5xl mx-auto px-4 mb-16">
    <h2 class="text-2xl font-bold mb-6 border-b pb-2">Results & Comparisons</h2>

    <div class="flex flex-col mb-8">
            <div class="group w-full bg-gray-100 rounded-lg relative border border-gray-200 hover:z-50 transition-all">
                <span class="absolute top-2 left-2 bg-purple-600/80 text-white text-xs px-2 py-1 rounded z-10 transition-opacity group-hover:opacity-0">Setup</span>
                <img 
                    src="./assets/f1.jpg" 
                    alt="System Setup" 
                    class="w-full h-auto object-contain rounded-lg bg-white hover:scale-110 transition duration-500 shadow-lg"
                >
            </div>
            <p class="text-center mt-2 text-sm font-medium">System Setup</p>
    </div>
    
    <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
        
        <div class="flex flex-col">
            <div class="group aspect-video bg-gray-100 rounded-lg relative border border-gray-200 hover:z-50 transition-all">
                <span class="absolute top-2 left-2 bg-black/50 text-white text-xs px-2 py-1 rounded z-10 transition-opacity group-hover:opacity-0">FPS</span>
                <img 
                    src="./assets/f2.jpg" 
                    alt="FPS"
                    class="w-full h-full object-contain rounded-lg bg-white hover:scale-[1.5] transition duration-500 shadow-lg"
                >
            </div>
            <p class="text-center mt-2 text-sm font-medium">FPS</p>
        </div>

        <div class="flex flex-col">
            <div class="group aspect-video bg-gray-100 rounded-lg relative border border-gray-200 hover:z-50 transition-all">
                <span class="absolute top-2 left-2 bg-blue-600/80 text-white text-xs px-2 py-1 rounded z-10 transition-opacity group-hover:opacity-0">Bandwidth</span>
                <img 
                    src="./assets/f3.jpg" 
                    alt="Bandwidth" 
                    class="w-full h-full object-contain rounded-lg bg-white hover:scale-[1.5] transition duration-500 shadow-lg"
                >
            </div>
            <p class="text-center mt-2 text-sm font-medium">Bandwidth</p>
        </div>

        <div class="flex flex-col">
            <div class="group aspect-video bg-gray-100 rounded-lg relative border border-gray-200 hover:z-50 transition-all">
                <span class="absolute top-2 left-2 bg-red-600/80 text-white text-xs px-2 py-1 rounded z-10 transition-opacity group-hover:opacity-0">Latency</span>
                <img 
                    src="./assets/f4.jpg" 
                    alt="Latency" 
                    class="w-full h-full object-contain rounded-lg bg-white hover:scale-[1.5] transition duration-500 shadow-lg"
                >
            </div>
            <p class="text-center mt-2 text-sm font-medium">End-to-end Latency</p>
        </div>

    </div>

    <section class="max-w-5xl mx-auto px-4 mb-16">
        <h2 class="text-2xl font-bold mb-6 border-b pb-2">Demos</h2>
        
        <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
            
            <div class="flex flex-col">
                <div class="aspect-video bg-gray-800 rounded-lg overflow-hidden relative">
                    <span class="absolute top-2 left-2 bg-black/50 text-white text-xs px-2 py-1 rounded">Demo 1</span>
                    <div class="w-full h-full flex items-center justify-center text-white/50">Demo Video 1</div>
                </div>
                <p class="text-center mt-2 text-sm font-medium">Demo Video 1</p>
            </div>

            <div class="flex flex-col">
                <div class="aspect-video bg-gray-800 rounded-lg overflow-hidden relative">
                    <span class="absolute top-2 left-2 bg-blue-600/80 text-white text-xs px-2 py-1 rounded">Demo 2</span>
                    <div class="w-full h-full flex items-center justify-center text-white/50">Demo Video 2</div>
                </div>
                <p class="text-center mt-2 text-sm font-medium">Demo Video 2</p>
            </div>

            <div class="flex flex-col">
                <div class="aspect-video bg-gray-800 rounded-lg overflow-hidden relative">
                    <span class="absolute top-2 left-2 bg-red-600/80 text-white text-xs px-2 py-1 rounded">Demo 3</span>
                    <div class="w-full h-full flex items-center justify-center text-white/50">Demo Video 3</div>
                </div>
                <p class="text-center mt-2 text-sm font-medium">Demo Video 3</p>
            </div>

        </div>
    </section>

    <section class="max-w-4xl mx-auto px-4 mb-16">
        <h2 class="text-2xl font-bold mb-4 border-b pb-2">License</h2>
        <p class="text-gray-700">
            This website is licensed under a <a rel="license" class="text-blue-600 hover:underline"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            <br>
            Sincerecely thank the authors of <a href="https://github.com/nerfies/nerfies.github.io" class="text-blue-600 hover:underline">Nerfies</a> for the template of this website.
        </p>
    </section>

</body>
</html>
